{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42cb48fc-caf4-4a7c-8d4d-4b68b2f198dd",
   "metadata": {},
   "source": [
    "### Implement the web scrapping on Amazon website or any shopping site by importing the requrests and the Beautiful Soup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83472d78-31fe-430c-b180-7d2b88dbbbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1. BeautifulSoup is a part of bs4 model. It is used for parsing HTML and XML documents. \\n    2. requests '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two Python libraries: Beautiful Soup and requests \n",
    "''' 1. BeautifulSoup is a part of bs4 model. It is used for parsing HTML and XML documents. \n",
    "    2. requests '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e0a2c3-bb5a-4d33-88f0-37feeeb7d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title: \n",
      "Product Price: \n",
      "Product Rating: \n",
      "Number of Reviews: \n",
      "Availability: Not Available\n",
      "✅ Data saved to product_info.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"span\", attrs={\"id\": \"productTitle\"})\n",
    "        title_string = title.get_text(strip=True) if title else \"\"\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={\"class\": \"a-offscreen\"})\n",
    "        price_string = price.get_text(strip=True) if price else \"\"\n",
    "    except AttributeError:\n",
    "        price_string = \"\"\n",
    "    return price_string\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(\"span\", attrs={\"class\": \"a-icon-alt\"})\n",
    "        rating_string = rating.get_text(strip=True) if rating else \"\"\n",
    "    except AttributeError:\n",
    "        rating_string = \"\"\n",
    "    return rating_string\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={\"id\": \"acrCustomerReviewText\"})\n",
    "        review_count_string = review_count.get_text(strip=True) if review_count else \"\"\n",
    "    except AttributeError:\n",
    "        review_count_string = \"\"\n",
    "    return review_count_string\n",
    "\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        availability = soup.find(\"div\", attrs={\"id\": \"availability\"})\n",
    "        availability_string = availability.get_text(strip=True) if availability else \"Not Available\"\n",
    "    except AttributeError:\n",
    "        availability_string = \"Not Available\"\n",
    "    return availability_string\n",
    "\n",
    "# Main block\n",
    "if __name__ == \"__main__\":\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "    }\n",
    "\n",
    "    url = \"https://www.amazon.in/Whirlpool-Semi-Automatic-Loading-Washing-Machine/dp/B09N9BKYN9/ref=sr_1_2_sspa?_encoding=UTF8&content-id=amzn1.sym.58c90a12-100b-4a2f-8e15-7c06f1abe2be&dib=eyJ2IjoiMSJ9.huIQjSkTuPfYXaUe3MtXkWA0dLO881tU6BS-vQHVB7xaMA60pMktorrxmEyRqWEGDXj5QyPf754sjDOyP_wEnzHTsHMhaF6TLYvgVsxjFplkjgR7YbKxA9KpVva0bj0rrLcot0Iar6_Bvz7hkBDpAi1uMiRNRpvNRuSDA1slBgzb1Wxrk5qXC6g3vQstajZvveWUqbqxpLgOH4bcDkUNO8ARQIr0N4-8cwTdN0jLuQRQJxyIBSlCxnU0TaBY0vOHHtqPcyeqRgu_i6MSIyu1KbOGttBEVg58JXgXzgrX2as.vDe6ANvM3-3txQdDTz4fvFQ33RmrgFzyjSVKiDVZsp4&dib_tag=se&pd_rd_r=f2be950f-de09-4379-804c-10d557328c77&pd_rd_w=NRsBA&pd_rd_wg=6uQQl&qid=1745574293&refinements=p_85%3A10440599031&rps=1&s=kitchen&sr=1-2-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGZfYnJvd3Nl&th=1\"\n",
    "\n",
    "    # HTTP Request\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "        # Soup Object containing all data\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extracting values\n",
    "        title = get_title(soup)\n",
    "        price = get_price(soup)\n",
    "        rating = get_rating(soup)\n",
    "        reviews = get_review_count(soup)\n",
    "        availability = get_availability(soup)\n",
    "\n",
    "        # Displaying on console\n",
    "        print(\"Product Title:\", title)\n",
    "        print(\"Product Price:\", price)\n",
    "        print(\"Product Rating:\", rating)\n",
    "        print(\"Number of Reviews:\", reviews)\n",
    "        print(\"Availability:\", availability)\n",
    "\n",
    "        # Saving to a text file\n",
    "        with open(\"product_info.txt\", \"a\", encoding=\"utf-8\") as file:\n",
    "            file.write(f\"Title: {title}\\n\")\n",
    "            file.write(f\"Price: {price}\\n\")\n",
    "            file.write(f\"Rating: {rating}\\n\")\n",
    "            file.write(f\"Reviews: {reviews}\\n\")\n",
    "            file.write(f\"Availability: {availability}\\n\")\n",
    "            file.write(\"=\"*40 + \"\\n\")\n",
    "\n",
    "        print(\"✅ Data saved to product_info.txt\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570f862-4da2-46a3-9773-56284ea53c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139c340-2015-4f1c-a553-c66336a9e1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
